{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOn5S4TNd0IYJ/Nz3ghPWNe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-r-m/experimental/blob/tesseract/tesseract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from random import randrange\n",
        "\n",
        "\n",
        "n = 3\n",
        "q = defaultdict(lambda: 0)\n",
        "training_sessions = 100000\n",
        "training_duration = 100\n"
      ],
      "metadata": {
        "id": "y-CUR9qTWTu5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hh7UuotJd3ab"
      },
      "outputs": [],
      "source": [
        "def initialize_state():\n",
        "  return list(range(n * (1 << n)))\n",
        "\n",
        "initial_state = initialize_state()\n",
        "\n",
        "\n",
        "def generate_permutations():\n",
        "  points, point_index_map = [], {}\n",
        "  for i in range(1 << n):\n",
        "    point = []\n",
        "    for _ in range(n):\n",
        "      point.append(((i & 1) * 2) - 1)\n",
        "      i >>= 1\n",
        "    for j in range(n):\n",
        "      current_point = point[::]\n",
        "      current_point[j] *= 2\n",
        "      point_index_map[tuple(current_point)] = len(points)\n",
        "      points.append(tuple(current_point))\n",
        "  permutations = [initialize_state()]\n",
        "  for i in range(n):\n",
        "    for j in range(i + 1, i + n):\n",
        "      for k in range(j + 1, i + n):\n",
        "        for l in range(1, 4):\n",
        "          permutation = initialize_state()\n",
        "          for point_index, point in enumerate(map(list, points)):\n",
        "            if point[i] < 0: continue\n",
        "            for _ in range(l):\n",
        "              point[j % n], point[k % n] = -point[k % n], point[j % n]\n",
        "            permutation[point_index_map[tuple(point)]] = point_index\n",
        "          permutations.append(permutation)\n",
        "  return permutations\n",
        "\n",
        "permutations = generate_permutations()\n",
        "\n",
        "\n",
        "def alignment(state):\n",
        "  return sum(i == pi for (i, pi) in enumerate(state))\n",
        "\n",
        "\n",
        "def apply(permutation, state):\n",
        "  next_state = list(map(lambda point_index: permutation[point_index], state))\n",
        "  return next_state, 10 * (alignment(next_state) - alignment(state)) - 1\n",
        "\n",
        "\n",
        "def scramble(d):\n",
        "  state = initialize_state()\n",
        "  for _ in range(d):\n",
        "    state, _ = apply(permutations[randrange(len(permutations))], state)\n",
        "  return state\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def policy(state):\n",
        "  return max(((q[(tuple(state), a)], a) for a in range(len(permutations))))[1]\n",
        "\n",
        "\n",
        "def train():\n",
        "  training_depth = 1\n",
        "  for i in range(training_sessions):\n",
        "    state = scramble(1 + randrange(training_depth))\n",
        "    if i % (training_sessions // training_duration) == 0:\n",
        "      training_depth += 1\n",
        "    for _ in range(training_duration):\n",
        "      for a in range(len(permutations)):\n",
        "        next_state, reward = apply(permutations[a], state)\n",
        "        q[(tuple(state), a)] = max(q[(tuple(state), a)],\n",
        "            reward + max(q[(tuple(next_state), b)] for b in range(len(permutations))))\n",
        "      state, _ = apply(state, permutations[policy(state)])\n",
        "\n",
        "train()\n"
      ],
      "metadata": {
        "id": "bTFGthUjWMpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  for _ in range(training_sessions):\n",
        "    state = scramble(1 + randrange(training_depth))\n",
        "    start, moves_made = state, 0\n",
        "    while state != initial_state:\n",
        "      state, _ = apply(state, permutations[policy(state)])\n",
        "      moves_made += 1\n",
        "    print(f\"{state} solved in {moves_made} moves\")\n",
        "\n",
        "test()\n"
      ],
      "metadata": {
        "id": "aGEUMYtV_0k9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}